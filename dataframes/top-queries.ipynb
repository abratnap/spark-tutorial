{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"TopQueries\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://9.24.0.127:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11a78afd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Read data form local filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = '../data/w3data/search-click-logs/2019*.avro' # Input path with REGEX to use the avro files\n",
    "OUTPUT_PATH = '../data/w3data/search-click-logs/output' # Output folder name to store generated reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from stores with given format\n",
    "\n",
    "#### Many Supported Data Sources \"CSV\", \"JSON\", \"parquet\", \"avro\", \"JDBC/ODBC\", \"Plain text\", \"HDFS\", \"Cassandra\", \"HBase\", \"MongoDb\" \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = spark.read.format(\"avro\").load(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- detectedDuplicate: boolean (nullable = true)\n",
      " |-- detectedCorruption: boolean (nullable = true)\n",
      " |-- firstInSession: boolean (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- remoteHost: string (nullable = true)\n",
      " |-- referer: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- viewportPixelWidth: integer (nullable = true)\n",
      " |-- viewportPixelHeight: integer (nullable = true)\n",
      " |-- screenPixelWidth: integer (nullable = true)\n",
      " |-- screenPixelHeight: integer (nullable = true)\n",
      " |-- partyId: string (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- pageViewId: string (nullable = true)\n",
      " |-- eventType: string (nullable = true)\n",
      " |-- userAgentString: string (nullable = true)\n",
      " |-- userAgentName: string (nullable = true)\n",
      " |-- userAgentFamily: string (nullable = true)\n",
      " |-- userAgentVendor: string (nullable = true)\n",
      " |-- userAgentType: string (nullable = true)\n",
      " |-- userAgentVersion: string (nullable = true)\n",
      " |-- userAgentDeviceCategory: string (nullable = true)\n",
      " |-- userAgentOsFamily: string (nullable = true)\n",
      " |-- userAgentOsVersion: string (nullable = true)\n",
      " |-- userAgentOsVendor: string (nullable = true)\n",
      " |-- page: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- rank: integer (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- resultType: string (nullable = true)\n",
      " |-- ibmer: string (nullable = true)\n",
      " |-- ibmEvType: string (nullable = true)\n",
      " |-- ibmEvAction: string (nullable = true)\n",
      " |-- ibmQuery: string (nullable = true)\n",
      " |-- queryID: string (nullable = true)\n",
      " |-- ibmSort: string (nullable = true)\n",
      " |-- ibmCountries: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ibmLanguages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ibmDate: string (nullable = true)\n",
      " |-- categoryId: string (nullable = true)\n",
      " |-- hkey: string (nullable = true)\n",
      " |-- documentDate: string (nullable = true)\n",
      " |-- dwellResultType: string (nullable = true)\n",
      " |-- dwellTime: string (nullable = true)\n",
      " |-- esqsOrSolr: string (nullable = true)\n",
      " |-- qtime: string (nullable = true)\n",
      " |-- organicResultsCount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+----------+\n",
      "|      ibmQuery|                 url|               title| ibmEvType|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "|  kyle freeman|https://w3.ibm.co...|FREEMAN, KYLE W (...|Dwell Time|\n",
      "|  what is BAIW|https://w3-connec...|Tech Support Appl...|Impression|\n",
      "|IBM counseling|https://w3-connec...|LA Legal Counsels...|Impression|\n",
      "|  what is BAIW|https://w3-connec...|STATS (BAIW) Refe...|Impression|\n",
      "|IBM counseling|https://d01db034....|MX-GS-0345 Rev. 1...|Impression|\n",
      "|  what is BAIW|https://w3-connec...|Creating user id ...|Impression|\n",
      "|          null|                null|                null|      null|\n",
      "|  what is BAIW|https://w3.ibm.co...|CEDP BAIW *APPLIC...|Impression|\n",
      "|    John petri|                null|                null|     Query|\n",
      "|    John petri|https://w3.ibm.co...|Petri, John E (John)|Impression|\n",
      "|  what is BAIW|https://w3.ibm.co...|CEDP BAIW ENTERCO...|Impression|\n",
      "|  recall email|                null|                null|     Query|\n",
      "|    John petri|https://w3-connec...|Rochester Master ...|Impression|\n",
      "|  recall email|https://w3.ibm.co...|Recall an Email Y...|Impression|\n",
      "|  what is BAIW|https://w3.ibm.co...|baiw_build_read *...|Impression|\n",
      "|    John petri|https://w3-connec...|Watson Health Inn...|Impression|\n",
      "|          null|                null|                null|      null|\n",
      "|  recall email|https://w3-connec...|    Watson Marketing|Impression|\n",
      "|  recall email|https://w3.ibm.co...|Compare Email Cli...|Impression|\n",
      "|    John petri|https://w3-connec...|     Instrumentation|Impression|\n",
      "+--------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_df.select(\"ibmQuery\", \"url\", \"title\", \"ibmEvType\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOP Queries ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_queries_df = metrics_df.select(\"ibmQuery\", \"ibmEvType\") \\\n",
    "        .where(col(\"ibmQuery\").isNotNull()) \\\n",
    "        .where (col(\"ibmEvType\") == \"Query\") \\\n",
    "        .groupBy(\"ibmQuery\") \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed('count', 'total')\\\n",
    "        .orderBy(\"total\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            ibmQuery|total|\n",
      "+--------------------+-----+\n",
      "|             workday|   11|\n",
      "|Client executive ...|   11|\n",
      "|          checkpoint|   10|\n",
      "|                 box|    9|\n",
      "|             buy@ibm|    8|\n",
      "|   service apartment|    7|\n",
      "|            itsc 300|    7|\n",
      "|              murali|    7|\n",
      "|Trans Tree Corpor...|    6|\n",
      "|tuition reimbursment|    6|\n",
      "|                bond|    5|\n",
      "|red hat enterpris...|    5|\n",
      "|                 pmr|    5|\n",
      "|               webex|    5|\n",
      "|time off service ...|    5|\n",
      "|   field engineering|    5|\n",
      "|           bluepages|    5|\n",
      "|    retiree benefits|    5|\n",
      "|                issi|    5|\n",
      "|    Offering manager|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_queries_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.registerTempTable(\"metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = spark.sql(\"SELECT ibmQuery, count(*) as total \"\n",
    "           \"FROM metrics \"\n",
    "           \"WHERE ibmQuery is NOT null AND ibmEvType == 'Query'\"\n",
    "           \"GROUP BY ibmQuery ORDER BY total desc \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            ibmQuery|total|\n",
      "+--------------------+-----+\n",
      "|             workday|   11|\n",
      "|Client executive ...|   11|\n",
      "|          checkpoint|   10|\n",
      "|                 box|    9|\n",
      "|             buy@ibm|    8|\n",
      "|              murali|    7|\n",
      "|   service apartment|    7|\n",
      "|            itsc 300|    7|\n",
      "|Trans Tree Corpor...|    6|\n",
      "|tuition reimbursment|    6|\n",
      "|                bond|    5|\n",
      "|               webex|    5|\n",
      "| career conversation|    5|\n",
      "|    Offering manager|    5|\n",
      "|   field engineering|    5|\n",
      "|red hat enterpris...|    5|\n",
      "|           bluepages|    5|\n",
      "|    retiree benefits|    5|\n",
      "|time off service ...|    5|\n",
      "|                issi|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical and Physical Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total DESC NULLS LAST], true\n",
      "+- Project [ibmQuery#33, count#141L AS total#144L]\n",
      "   +- Aggregate [ibmQuery#33], [ibmQuery#33, count(1) AS count#141L]\n",
      "      +- Filter (ibmEvType#31 = Query)\n",
      "         +- Filter isnotnull(ibmQuery#33)\n",
      "            +- Project [ibmQuery#33, ibmEvType#31]\n",
      "               +- Relation[detectedDuplicate#0,detectedCorruption#1,firstInSession#2,timestamp#3L,remoteHost#4,referer#5,location#6,viewportPixelWidth#7,viewportPixelHeight#8,screenPixelWidth#9,screenPixelHeight#10,partyId#11,sessionId#12,pageViewId#13,eventType#14,userAgentString#15,userAgentName#16,userAgentFamily#17,userAgentVendor#18,userAgentType#19,userAgentVersion#20,userAgentDeviceCategory#21,userAgentOsFamily#22,userAgentOsVersion#23,... 23 more fields] avro\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ibmQuery: string, total: bigint\n",
      "Sort [total#144L DESC NULLS LAST], true\n",
      "+- Project [ibmQuery#33, count#141L AS total#144L]\n",
      "   +- Aggregate [ibmQuery#33], [ibmQuery#33, count(1) AS count#141L]\n",
      "      +- Filter (ibmEvType#31 = Query)\n",
      "         +- Filter isnotnull(ibmQuery#33)\n",
      "            +- Project [ibmQuery#33, ibmEvType#31]\n",
      "               +- Relation[detectedDuplicate#0,detectedCorruption#1,firstInSession#2,timestamp#3L,remoteHost#4,referer#5,location#6,viewportPixelWidth#7,viewportPixelHeight#8,screenPixelWidth#9,screenPixelHeight#10,partyId#11,sessionId#12,pageViewId#13,eventType#14,userAgentString#15,userAgentName#16,userAgentFamily#17,userAgentVendor#18,userAgentType#19,userAgentVersion#20,userAgentDeviceCategory#21,userAgentOsFamily#22,userAgentOsVersion#23,... 23 more fields] avro\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total#144L DESC NULLS LAST], true\n",
      "+- Aggregate [ibmQuery#33], [ibmQuery#33, count(1) AS total#144L]\n",
      "   +- Project [ibmQuery#33]\n",
      "      +- Filter ((isnotnull(ibmEvType#31) && isnotnull(ibmQuery#33)) && (ibmEvType#31 = Query))\n",
      "         +- Relation[detectedDuplicate#0,detectedCorruption#1,firstInSession#2,timestamp#3L,remoteHost#4,referer#5,location#6,viewportPixelWidth#7,viewportPixelHeight#8,screenPixelWidth#9,screenPixelHeight#10,partyId#11,sessionId#12,pageViewId#13,eventType#14,userAgentString#15,userAgentName#16,userAgentFamily#17,userAgentVendor#18,userAgentType#19,userAgentVersion#20,userAgentDeviceCategory#21,userAgentOsFamily#22,userAgentOsVersion#23,... 23 more fields] avro\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [total#144L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(total#144L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[ibmQuery#33], functions=[count(1)], output=[ibmQuery#33, total#144L])\n",
      "      +- Exchange hashpartitioning(ibmQuery#33, 200)\n",
      "         +- *(1) HashAggregate(keys=[ibmQuery#33], functions=[partial_count(1)], output=[ibmQuery#33, count#154L])\n",
      "            +- *(1) Project [ibmQuery#33]\n",
      "               +- *(1) Filter ((isnotnull(ibmEvType#31) && isnotnull(ibmQuery#33)) && (ibmEvType#31 = Query))\n",
      "                  +- *(1) FileScan avro [ibmEvType#31,ibmQuery#33] Batched: false, Format: org.apache.spark.sql.avro.AvroFileFormat@2ea71000, Location: InMemoryFileIndex[file:/Users/abhay/learning/spark-tutorial/data/w3data/search-click-logs/2019082..., PartitionFilters: [], PushedFilters: [IsNotNull(ibmEvType), IsNotNull(ibmQuery), EqualTo(ibmEvType,Query)], ReadSchema: struct<ibmEvType:string,ibmQuery:string>\n"
     ]
    }
   ],
   "source": [
    "top_queries_df.explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['total DESC NULLS LAST], true\n",
      "+- 'Aggregate ['ibmQuery], ['ibmQuery, 'count(1) AS total#137]\n",
      "   +- 'Filter (isnotnull('ibmQuery) && ('ibmEvType = Query))\n",
      "      +- 'UnresolvedRelation `metrics`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ibmQuery: string, total: bigint\n",
      "Sort [total#137L DESC NULLS LAST], true\n",
      "+- Aggregate [ibmQuery#33], [ibmQuery#33, count(1) AS total#137L]\n",
      "   +- Filter (isnotnull(ibmQuery#33) && (ibmEvType#31 = Query))\n",
      "      +- SubqueryAlias `metrics`\n",
      "         +- Relation[detectedDuplicate#0,detectedCorruption#1,firstInSession#2,timestamp#3L,remoteHost#4,referer#5,location#6,viewportPixelWidth#7,viewportPixelHeight#8,screenPixelWidth#9,screenPixelHeight#10,partyId#11,sessionId#12,pageViewId#13,eventType#14,userAgentString#15,userAgentName#16,userAgentFamily#17,userAgentVendor#18,userAgentType#19,userAgentVersion#20,userAgentDeviceCategory#21,userAgentOsFamily#22,userAgentOsVersion#23,... 23 more fields] avro\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [total#137L DESC NULLS LAST], true\n",
      "+- Aggregate [ibmQuery#33], [ibmQuery#33, count(1) AS total#137L]\n",
      "   +- Project [ibmQuery#33]\n",
      "      +- Filter ((isnotnull(ibmEvType#31) && isnotnull(ibmQuery#33)) && (ibmEvType#31 = Query))\n",
      "         +- Relation[detectedDuplicate#0,detectedCorruption#1,firstInSession#2,timestamp#3L,remoteHost#4,referer#5,location#6,viewportPixelWidth#7,viewportPixelHeight#8,screenPixelWidth#9,screenPixelHeight#10,partyId#11,sessionId#12,pageViewId#13,eventType#14,userAgentString#15,userAgentName#16,userAgentFamily#17,userAgentVendor#18,userAgentType#19,userAgentVersion#20,userAgentDeviceCategory#21,userAgentOsFamily#22,userAgentOsVersion#23,... 23 more fields] avro\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) Sort [total#137L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(total#137L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[ibmQuery#33], functions=[count(1)], output=[ibmQuery#33, total#137L])\n",
      "      +- Exchange hashpartitioning(ibmQuery#33, 200)\n",
      "         +- *(1) HashAggregate(keys=[ibmQuery#33], functions=[partial_count(1)], output=[ibmQuery#33, count#149L])\n",
      "            +- *(1) Project [ibmQuery#33]\n",
      "               +- *(1) Filter ((isnotnull(ibmEvType#31) && isnotnull(ibmQuery#33)) && (ibmEvType#31 = Query))\n",
      "                  +- *(1) FileScan avro [ibmEvType#31,ibmQuery#33] Batched: false, Format: org.apache.spark.sql.avro.AvroFileFormat@7a1b8084, Location: InMemoryFileIndex[file:/Users/abhay/learning/spark-tutorial/data/w3data/search-click-logs/2019082..., PartitionFilters: [], PushedFilters: [IsNotNull(ibmEvType), IsNotNull(ibmQuery), EqualTo(ibmEvType,Query)], ReadSchema: struct<ibmEvType:string,ibmQuery:string>\n"
     ]
    }
   ],
   "source": [
    "sql_df.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions, Repartitions, and coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_queries_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_queries_df.repartition(50).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_queries_df.coalesce(2).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_queries_df.coalesce(1).write.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\", \"false\")\\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", \"false\")\\\n",
    "    .save(OUTPUT_PATH+\"/top-queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
