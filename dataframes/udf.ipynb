{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"TopDomains\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.format(\"csv\").load(\"../data/w3data/nutch_URLs_0422/PRD_nutch_urls_20200422.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.read.format(\"csv\").load(\"../data/w3data/nutch_URLs_0422/PRD_nutch1_urls_20200422.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706251"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112630"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.select(col(\"_c0\").alias(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.select(col(\"_c0\").alias(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "@udf\n",
    "def getHost(url):\n",
    "    #parsed_uri = urlparse('http://stackoverflow.com/questions/1234567/blah-blah-blah-blah' )\n",
    "    #result = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "    return urlparse(url).hostname\n",
    "    #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import os.path\n",
    "\n",
    "@udf\n",
    "def getPathOne(url):\n",
    "    #parsed_uri = urlparse('http://stackoverflow.com/questions/1234567/blah-blah-blah-blah' )\n",
    "    #result = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "    #return urlparse(url).hostname\n",
    "    #return result\n",
    "    path = urlparse(url).path\n",
    "    paths = path.split('/')\n",
    "    if len(paths) > 1 :\n",
    "        return paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import os.path\n",
    "\n",
    "@udf\n",
    "def getPathTwo(url):\n",
    "    #parsed_uri = urlparse('http://stackoverflow.com/questions/1234567/blah-blah-blah-blah' )\n",
    "    #result = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
    "    #return urlparse(url).hostname\n",
    "    #return result\n",
    "    path = urlparse(url).path\n",
    "    paths = path.split('/')\n",
    "    if len(paths) > 2 :\n",
    "        return paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def getHostId(url):\n",
    "     return url.split(':')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def getProtocol(url):\n",
    "    paths = url.split(':')\n",
    "    if len(paths) > 1 :\n",
    "        return paths[1].split('/')[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def getPath1(url):\n",
    "    paths = url.split(':')\n",
    "    if len(paths) > 1 :\n",
    "        paths2 = paths[1].split('/')\n",
    "        if len(paths2) > 1:\n",
    "            return paths2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def getPath2(url):\n",
    "    paths = url.split(':')\n",
    "    if len(paths) > 1 :\n",
    "        paths2 = paths[1].split('/')\n",
    "        if len(paths2) > 2 :\n",
    "            return paths2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def getPath2(url):\n",
    "    paths = url.split(':')\n",
    "    if len(paths) > 1 :\n",
    "        paths2 = paths[1].split('/')\n",
    "        if len(paths2) > 2 :\n",
    "            return paths2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostDf = df.withColumn('domain', getHost('url'))\n",
    "hostDf = hostDf.withColumn('path1', getPathOne('url'))\n",
    "hostDf = hostDf.withColumn('path2', getPathTwo('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hostDf = hostDf.withColumn('protocol', getProtocol('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hostDf = hostDf.withColumn('path1', getPath1('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hostDf = hostDf.withColumn('path2', getPath2('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostDf1 = df1.withColumn('domain', getHost('url'))\n",
    "hostDf1 = hostDf1.withColumn('path1', getPathOne('url'))\n",
    "hostDf1 = hostDf1.withColumn('path2', getPathTwo('url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- path1: string (nullable = true)\n",
      " |-- path2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- path1: string (nullable = true)\n",
      " |-- path2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostDf1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT domain)|\n",
      "+----------------------+\n",
      "|                    40|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "hostDf.select(countDistinct('domain')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|         path1|\n",
      "+--------------+\n",
      "|          null|\n",
      "|              |\n",
      "|    activities|\n",
      "|         appid|\n",
      "|         appid|\n",
      "|        impact|\n",
      "|        impact|\n",
      "|        impact|\n",
      "|   initiatives|\n",
      "|   initiatives|\n",
      "|responsibility|\n",
      "|responsibility|\n",
      "|responsibility|\n",
      "|responsibility|\n",
      "|    activities|\n",
      "|    activities|\n",
      "|    activities|\n",
      "|    activities|\n",
      "|    activities|\n",
      "|    activities|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostDf.select('path1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostnames = hostDf.select(\"domain\", \"path1\") \\\n",
    "           .groupBy(\"domain\", \"path1\")\\\n",
    "           .count()\\\n",
    "           .withColumnRenamed(\"count\",\"nutch2count\")\\\n",
    "           .orderBy(\"nutch2count\", ascending=False)#\\\n",
    "           #.show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostnames1 = hostDf1.select(\"domain\", \"path1\") \\\n",
    "           .groupBy(\"domain\",\"path1\")\\\n",
    "           .count()\\\n",
    "            .withColumnRenamed(\"count\",\"nutch1count\")\\\n",
    "           .orderBy(\"count\", ascending=False)\n",
    "           #.show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- domain: string (nullable = true)\n",
      " |-- path1: string (nullable = true)\n",
      " |-- nutch2count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostnames.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutch1v2 = hostnames1.join(hostnames, on=['domain', 'path1'], how='outer')\\\n",
    "                 .orderBy(\"nutch2count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-----------------------+-----------+-----------+\n",
      "|domain                             |path1                  |nutch1count|nutch2count|\n",
      "+-----------------------------------+-----------------------+-----------+-----------+\n",
      "|www.ibm.com                        |blogs                  |40370      |228736     |\n",
      "|developer.ibm.com                  |answers                |null       |160757     |\n",
      "|procure.sby1.ibm.com               |whk                    |1906       |86669      |\n",
      "|w3-03.ibm.com                      |services               |361        |78741      |\n",
      "|d01db034.pok.ibm.com               |q_dir                  |37139      |73962      |\n",
      "|w3-01.ibm.com                      |hr                     |1157       |10137      |\n",
      "|productpages.w3ibm.mybluemix.net   |ProductPages           |204        |6511       |\n",
      "|incentivesworkplace.atlanta.ibm.com|node                   |1          |5223       |\n",
      "|secure.video.ibm.com               |channel                |1490       |3651       |\n",
      "|developer.ibm.com                  |tv                     |null       |3343       |\n",
      "|developer.ibm.com                  |profiles               |null       |3086       |\n",
      "|developer.ibm.com                  |recipes                |null       |3036       |\n",
      "|incentivesworkplace.atlanta.ibm.com|sites                  |null       |2407       |\n",
      "|www.ibm.com                        |cloud                  |2          |2369       |\n",
      "|developer.ibm.com                  |code                   |null       |1957       |\n",
      "|w3-03.ibm.com                      |globalization          |null       |1808       |\n",
      "|developer.ibm.com                  |integration            |null       |1465       |\n",
      "|developer.ibm.com                  |dwblog                 |null       |1270       |\n",
      "|developer.ibm.com                  |kr                     |null       |1269       |\n",
      "|developer.ibm.com                  |apiconnect             |null       |1251       |\n",
      "|bluepedia.w3ibm.mybluemix.net      |index.php              |6604       |1151       |\n",
      "|developer.ibm.com                  |hadoop                 |null       |1036       |\n",
      "|developer.ibm.com                  |customer-engagement    |null       |1031       |\n",
      "|developer.ibm.com                  |wasdev                 |null       |980        |\n",
      "|developer.ibm.com                  |mainframe              |null       |931        |\n",
      "|developer.ibm.com                  |urbancode              |null       |901        |\n",
      "|developer.ibm.com                  |opentech               |null       |818        |\n",
      "|w3.ibm.com                         |developer              |400        |784        |\n",
      "|developer.ibm.com                  |predictiveanalytics    |null       |763        |\n",
      "|developer.ibm.com                  |apm                    |null       |722        |\n",
      "|blueprint.sl.bluecloud.ibm.com     |b_dir                  |3          |602        |\n",
      "|developer.ibm.com                  |clouddataservices      |null       |597        |\n",
      "|developer.ibm.com                  |messaging              |null       |585        |\n",
      "|developer.ibm.com                  |events                 |null       |583        |\n",
      "|w3.ibm.com                         |thinkacademy           |1          |567        |\n",
      "|developer.ibm.com                  |bpm                    |null       |563        |\n",
      "|developer.ibm.com                  |storage                |null       |560        |\n",
      "|developer.ibm.com                  |tutorials              |null       |557        |\n",
      "|developer.ibm.com                  |linuxonpower           |null       |542        |\n",
      "|developer.ibm.com                  |streamsdev             |null       |536        |\n",
      "|developer.ibm.com                  |patterns               |null       |491        |\n",
      "|developer.ibm.com                  |cics                   |null       |475        |\n",
      "|w3.itso.ibm.com                    |itsoapps               |550        |461        |\n",
      "|developer.ibm.com                  |articles               |null       |456        |\n",
      "|incentivesworkplace.atlanta.ibm.com|video                  |null       |453        |\n",
      "|developer.ibm.com                  |node                   |null       |452        |\n",
      "|developer.ibm.com                  |digexp                 |null       |450        |\n",
      "|ibmdev.webmaster.ibm.com           |v18                    |420        |439        |\n",
      "|developer.ibm.com                  |testing                |null       |426        |\n",
      "|developer.ibm.com                  |blogs                  |null       |414        |\n",
      "|developer.ibm.com                  |swift                  |null       |403        |\n",
      "|w3.ibm.com                         |hr                     |9690       |391        |\n",
      "|prodpcbhrfaq03.w3-969.ibm.com      |index.php              |null       |386        |\n",
      "|developer.ibm.com                  |cn                     |null       |349        |\n",
      "|developer.ibm.com                  |videos                 |null       |276        |\n",
      "|w3-01.ibm.com                      |services               |299        |270        |\n",
      "|w3-03.ibm.com                      |support                |1214       |264        |\n",
      "|developer.ibm.com                  |jp                     |null       |245        |\n",
      "|developer.ibm.com                  |identitydev            |null       |239        |\n",
      "|developer.ibm.com                  |iotplatform            |null       |236        |\n",
      "|developer.ibm.com                  |docloud                |null       |216        |\n",
      "|www.research.ibm.com               |artificial-intelligence|750        |200        |\n",
      "|learn.atlanta.ibm.com              |la                     |528        |192        |\n",
      "|incentivesworkplace.atlanta.ibm.com|taxonomy               |null       |184        |\n",
      "|developer.ibm.com                  |powervc                |null       |163        |\n",
      "|w3.itso.ibm.com                    |abstracts              |359        |161        |\n",
      "|developer.ibm.com                  |odm                    |null       |160        |\n",
      "|developer.ibm.com                  |api                    |null       |153        |\n",
      "|www.ibm.com                        |developerworks         |null       |150        |\n",
      "|w3.ibm.com                         |transform              |73         |144        |\n",
      "|prodpcrhrfaq01.w3-969.ibm.com      |systemstorage          |null       |132        |\n",
      "|developer.ibm.com                  |announcements          |null       |130        |\n",
      "|developer.ibm.com                  |cloudautomation        |null       |128        |\n",
      "|developer.ibm.com                  |itom                   |null       |128        |\n",
      "|developer.ibm.com                  |in                     |null       |127        |\n",
      "|developer.ibm.com                  |series                 |null       |123        |\n",
      "|developer.ibm.com                  |open                   |null       |123        |\n",
      "|developer.ibm.com                  |watsonhealth           |null       |121        |\n",
      "|prodpcrhrfaq01.w3-969.ibm.com      |powersystems           |null       |112        |\n",
      "|developer.ibm.com                  |data                   |null       |110        |\n",
      "|cedp-kc-doc.w3ibm.mybluemix.net    |CEDP                   |439        |107        |\n",
      "|prodpcbhrfaq03.w3-969.ibm.com      |tooling-project        |null       |105        |\n",
      "|developer.ibm.com                  |exchanges              |null       |101        |\n",
      "|w3-01.ibm.com                      |chq                    |169        |96         |\n",
      "|developer.ibm.com                  |qradar                 |null       |94         |\n",
      "|developer.ibm.com                  |javasdk                |null       |88         |\n",
      "|w3.ibm.com                         |tools                  |215        |87         |\n",
      "|developer.ibm.com                  |sso                    |null       |84         |\n",
      "|developer.ibm.com                  |components             |null       |84         |\n",
      "|prodpcbhrfaq03.w3-969.ibm.com      |user                   |null       |79         |\n",
      "|w3.itso.ibm.com                    |redbooks               |null       |77         |\n",
      "|incentivesworkplace.atlanta.ibm.com|asca                   |null       |75         |\n",
      "|developer.ibm.com                  |technologies           |null       |75         |\n",
      "|prodpcbhrfaq03.w3-969.ibm.com      |taxonomy               |null       |59         |\n",
      "|gbs-qms.w3ibm.mybluemix.net        |template               |160        |57         |\n",
      "|incentivesworkplace.atlanta.ibm.com|plan-cycle             |null       |56         |\n",
      "|developer.ibm.com                  |watson                 |null       |54         |\n",
      "|developer.ibm.com                  |courses                |null       |50         |\n",
      "|incentivesworkplace.atlanta.ibm.com|incremental-incentives |null       |50         |\n",
      "|developer.ibm.com                  |code-and-response      |null       |47         |\n",
      "+-----------------------------------+-----------------------+-----------+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nutch1v2.show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'USING column `path1` cannot be resolved on the left side of the join. The left-side columns: [domain, nutch1count];'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o840.join.\n: org.apache.spark.sql.AnalysisException: USING column `path1` cannot be resolved on the left side of the join. The left-side columns: [domain, nutch1count];\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$98$$anonfun$apply$71.apply(Analyzer.scala:2337)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$98$$anonfun$apply$71.apply(Analyzer.scala:2337)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$98.apply(Analyzer.scala:2336)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$98.apply(Analyzer.scala:2335)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$commonNaturalJoinProcessing(Analyzer.scala:2335)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin$$anonfun$apply$34.applyOrElse(Analyzer.scala:2225)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin$$anonfun$apply$34.applyOrElse(Analyzer.scala:2222)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin$.apply(Analyzer.scala:2222)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveNaturalAndUsingJoin$.apply(Analyzer.scala:2221)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:55)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:47)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3406)\n\tat org.apache.spark.sql.Dataset.join(Dataset.scala:938)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-304fe471b672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnutch1v2_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhostnames1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostnames\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'path1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nutch2count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                 \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"how should be basestring\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'USING column `path1` cannot be resolved on the left side of the join. The left-side columns: [domain, nutch1count];'"
     ]
    }
   ],
   "source": [
    "nutch1v2_2 = hostnames1.join(hostnames,  how='outer', on=['domain','path1'])\\\n",
    "                 .orderBy(\"nutch2count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|path1|  count|\n",
      "+-----+-------+\n",
      "|blogs|3178314|\n",
      "|  ibm|   2279|\n",
      "|cloud|   1674|\n",
      "|demos|     18|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostnames = hostDf.select(\"domain\",  \"path1\", \"path2\") \\\n",
    "           .where(col(\"domain\") == \"com.ibm.www\") \\\n",
    "           .groupBy(\"path1\")\\\n",
    "           .count()\\\n",
    "           .orderBy(\"count\", ascending=False)\\\n",
    "           .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|path1|count|\n",
      "+-----+-----+\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hostnames.show(200, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
